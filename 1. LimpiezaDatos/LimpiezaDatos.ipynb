{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " <img src='../Imagenes/Diplomado.jpg' style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 120%;\">\n",
    "\n",
    "  <link rel=\"stylesheet\" href=\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css\" integrity=\"sha512-xh6O/CkQoPOWDdYTDqeRdPCVd1SpvCA9XXcUnZS2FmJNp1coAFzvtCN9BmamE+4aHK8yyUHUSCcJHgXloTyT2A==\" crossorigin=\"anonymous\" referrerpolicy=\"no-referrer\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capítulo 1: Limpieza de Datos\n",
    "### Desarrollado por: Ing. Julian Quimbayo Castro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h2><a id=\"11\"><i class=\"fa fa-star fa-1x\" aria-hidden=\"true\" style=\"color:blue\"></i> Agenda de Trabajo</a></h2> \n",
    "<hr>\n",
    "\n",
    "- [1. Introducción](#1)\n",
    "- [2. Imputación de datos NAN](#2)\n",
    "- [3. Formas de Reemplazo NAN](#3)\n",
    "- [4. Datos Numéricos a Texto](#4)\n",
    "- [5. Datos texto a numérico](#5)\n",
    "- [6. One Hot Encoder y label encoder](#6)\n",
    "- [7. Partición Dataframes](#7)\n",
    "- [8. Oversampling y undersampling](#8)\n",
    "- [9. Normalización y estandarización](#9)\n",
    "- [10. Correlaciones Pearson y Spearman](#10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><i class=\"fa-solid fa-lightbulb fa-1x\" style=\"color:blue\"></i> Objetivos de la Sesión:</h2> \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Implementar el uso de python para limpieza de datos NAN (Not a Number)\n",
    "- Imputar NAN para datos numéricos (media, mediana)\n",
    "- Imputar NAN para datos categóricos (moda)\n",
    "- Cambiar datos numéricos a categóricos y viceversa.\n",
    "- Uso de One Hot Enconder y Label Encoder\n",
    "- Particionar Dataframe\n",
    "- Normalización y Estandarización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"1\">1. Introducción</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dentro del ciclo de vida de ciencia de datos en especial cualquier proyecto de **machine learning** es la fase de limpieza de datos; dentro de estos procesos hace parte la **limpieza de datos NAN**, cambio de datos **numéricos a categóricos y viceversa**, **binarización de datos**, **partición y normalización de datos**.\n",
    "\n",
    "<img src='../Imagenes/cleaning.jpg' style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"2\">2. Imputación de datos NAN</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos NAN son datos vacíos o dañados en los dataframes, a menudo se representan por un simbolo de **NAN** o en otros lenguajes **NA**, estos datos dependiendo de su tipología se deben tratar, existen muchas maneras de realizarlo.\n",
    "\n",
    "<img src='../Imagenes/nan.png' style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "Algunos de los casos de valores NAN son: MCAR(Missing Completely At Random) , MNAR (Missing Not At Random), MAR(Missing At Random)\n",
    "\n",
    "<img src='../Imagenes/Random.png' style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 40%;\">\n",
    "\n",
    "- **MCAR**: En el MCAR, la probabilidad de que falten datos es la misma para todas las observaciones. En este caso, no hay relación entre los datos que faltan y cualquier otro valor observado o no observado (los datos que no se registran) dentro del conjunto de datos dado. Es decir, los valores que faltan son completamente independientes de otros datos. No hay ningún patrón. En el caso de MCAR, los datos pueden faltar debido a un error humano, a un fallo del sistema/equipo, a la pérdida de la muestra o a algún detalle técnico insatisfactorio al registrar los valores.\n",
    "\n",
    "- **MNAR**: Los valores perdidos dependen de los datos no observados. Si hay alguna estructura/patrón en los datos que faltan y otros datos observados no pueden explicarlos, entonces se trata de datos perdidos no aleatorios (MNAR). Si los datos que faltan no entran en la categoría MCAR o MAR, entonces pueden clasificarse como MNAR. Puede ocurrir debido a la reticencia de las personas a proporcionar la información requerida. Un grupo específico de personas puede no responder a algunas preguntas en una encuesta.\n",
    "\n",
    "- **MAR**: Los datos faltantes al azar (MAR) significan que la razón de los valores faltantes puede ser explicada por las variables sobre las que se tiene información completa, ya que existe alguna relación entre los datos faltantes y otros valores/datos. En este caso, los datos no faltan en todas las observaciones. Sólo faltan en submuestras de los datos y hay algún patrón en los valores que faltan.\n",
    "\n",
    "Nota: **lo último que se debe hacer es eliminar la data sean columnas o filas.**; si el porcentaje de datos NAN es superior al 25% total de la data.\n",
    "\n",
    "[Volver a Casa](#11)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"3\">3. Formas de Reemplazo NAN</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reemplazar con un datos arbitrario valores **numéricos**: se asigna por defecto un valor arbitrario que no afecte la columna.\n",
    "\n",
    "<img src=\"../Imagenes/reem1.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 100%;\">\n",
    "\n",
    "- Reemplazar con la media o mediana los valores numéricos: se asigna un valor medio o mediano dependiendo de la grafica de histograma asumiendo que los datos vienen de un población con tendencia a la campana de Gauss o datos normales.\n",
    "\n",
    "<img src=\"../Imagenes/reem2.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 100%;\">\n",
    "\n",
    "<img src=\"../Imagenes/testN.jpg\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 100%;\">\n",
    "\n",
    "Cuando la gráfica de histograma tiende hacia la derecha o izquierda se reemplaza con la **mediana** cuando tienen forma de campana se reemplaza con la **media**.\n",
    "\n",
    "<img src=\"../Imagenes/reem3.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "- Reemplazar con el valor que más se repite - **categóricos**: \n",
    "\n",
    "<img src=\"../Imagenes/reem4.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "La palabra reservada mode()[0], hace referencia al valor mas repetido dentro de la distribución categórica.\n",
    "\n",
    "- Reemplazo con valores hacia atras(Backward fill) o hacia adelante (Forward fill)\n",
    "\n",
    "<img src=\"../Imagenes/reem5.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "Nota: Se debe tener cuidado con que los tipos de datos este correctos de lo contrario se complicará mas el ejercicio.\n",
    "\n",
    "- Reemplazo con algoritmos de Machine Learning - Scikit Learn (KNN Imputer)\n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"4\">4. Datos numéricos a texto</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para convertir datos numéricos a texto se utiliza el operador ternario np.where, donde a través de una condición se valida si encuentra el valor dado el caso se asigna el valor de reemplazo.\n",
    "<img src=\"../Imagenes/reem7.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"5\">5. Datos texto a numérico</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las maneras mas sencillas para cambiar datos de tipo numérico a texto es la función **np.where**, la cual funciona como un operador ternario.\n",
    "<img src=\"../Imagenes/reem6.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "En donde siempre se llama la columna a modificar se iguala a np.where y se genera una condición en caso de ser verdadera en este caso si encuentra la palabra masculino convierte el dato a uno de lo contrario para femenino convierte a cero.\n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"6\">6. One Hot Encoder y label encoder</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las formas más tradicionales y efectivas para convertir valores textuales (categóricos) a numéricos son los enconders, estos permiten llevar a valores binarios o de distintos valores las categorías de las columnas.\n",
    "<img src=\"../Imagenes/reem8.jpeg\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "- Label Encoder: \n",
    "La codificación de etiquetas es una técnica de codificación muy popular para manejar variables categóricas. En esta técnica, a cada etiqueta se le asigna un número entero único basado en el orden alfabético.\n",
    "<img src=\"../Imagenes/reem9.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 50%;\">\n",
    "\n",
    "<img src=\"../Imagenes/reem10.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 50%;\">\n",
    "\n",
    "Como se evidencia de manera alfabética se realiza la asignación de valores para el hospital carmen emilia el valor de cero, para Medilaser el valor de uno y dos para el hospital Moncaleano; esto supone que en un modelo predictivo posiblemente existirá correlación entre estas variables por tal motivo se deben binarizar por medio de las variables dummies o como se conoce el one hot encoder.\n",
    "\n",
    "- One Hot Encoder:\n",
    "La codificación en caliente es otra técnica popular para tratar las variables categóricas. Simplemente crea características adicionales basadas en el número de valores únicos en la característica categórica. Cada valor único de la categoría se añadirá como característica.\n",
    "<img src=\"../Imagenes/reem11.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "<img src=\"../Imagenes/reem12.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "Como se pueden dar cuenta se binariza cada variable siendo cero(0) donde el registro no pertenece a esa categoría de hospital y uno(1) si realmente pertenece; dado que no es muy óptimo tener los nombres con las categorías 0,1 y 2 se proceden a renombrar.\n",
    "\n",
    "<img src=\"../Imagenes/reem13.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "<span style=\"color:blue\">Nota: este proceso de one hot encoder se realiza cuando las categorías son mayores a dos.</span>\n",
    "\n",
    "[Volver a Casa](#11) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"7\">7. Partición Dataframes</a>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para realizar particiones la mejor manera es utilizar la función iloc que permite porcionar de acuerdo a la relación filas y columnas. Con dicha función la relación si colocamos df.iloc[3:50, [0,1,5]], quiere decir que tomamos filas de la 3 a la 49 y las columnas Edad, Genero y CovDiag.\n",
    "<img src=\"../Imagenes/reem14.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"8\">8. Oversampling y undersamplig</a>\n",
    "<hr>\n",
    "\n",
    "Uno de los problemas más grandes es el balanceo del dataset con base en la variable que se va a escoger como **predictora o clasificadora**, es por esta situación y con el fin de que el algoritmo de machine learning actúe con coherencia existe las técnicas de resample (OverSampling y UnderSampling).\n",
    "\n",
    "<img src=\"../Imagenes/overunder.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 80%;\">\n",
    "\n",
    "1. **Oversampling:** \n",
    "permite tomar la clase minoritaria y nivelarla con base en la mayoritaria.\n",
    "\n",
    "1. **Undersampling:** \n",
    "permite tomar la clase mayoritaria y nivelarla con base en la minoritaria.\n",
    "\n",
    "Ambos resultados se deben probar por medio de un algoritmo de machine learning ya que a simple vista no es posible determinar cual es el más eficiente si un dataset a la alta o a la baja.\n",
    "\n",
    "- **OverSampling**:\n",
    "\n",
    "#### Oversampling y undersampling - nivelar el dataset con la variable que va a ser mi predictora o clasificadora\n",
    "dataF['CovidD'].value_counts()\n",
    "\n",
    "#### paso uno separar las clases - mayoritaria y minoritaria\n",
    "\n",
    "dataFMayor = dataF[dataF.CovidD==0]\n",
    "\n",
    "dataFMenor = dataF[dataF.CovidD==1]\n",
    "\n",
    "#### Over Sampling sobre la clase minoritaria\n",
    "\n",
    "df_minoritaria = resample(dataFMenor, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=60,    \n",
    "                                 random_state=123)\n",
    " \n",
    "#### Combina la clase mayoritaria con la minoritaria nivelada\n",
    "\n",
    "df_Over = pd.concat([dataFMayor, df_minoritaria])\n",
    " \n",
    "#### Muestra el resultado final\n",
    "\n",
    "df_Over.CovidD.value_counts()\n",
    "\n",
    "<img src=\"../Imagenes/resover.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "- **UnderSampling**:\n",
    "\n",
    "#### Under Sampling sobre la clase mayoritaria\n",
    "\n",
    "df_mayoritaria = resample(dataFMayor, \n",
    "                                 replace=False,     \n",
    "                                 n_samples=39,    \n",
    "                                 random_state=123)\n",
    " \n",
    "#### Combina la clase minoritaria con la mayoritaria nivelada a la baja\n",
    "\n",
    "df_Under = pd.concat([df_mayoritaria, dataFMenor])\n",
    " \n",
    "#### Muestra el resultado final\n",
    "df_Under.CovidD.value_counts()\n",
    "\n",
    "<img src=\"../Imagenes/resunder.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "[Volver a Casa](#11) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"9\">9. Normalización y estandarización</a>\n",
    "<hr>\n",
    "\n",
    "1. **La Normalización:**\n",
    "\n",
    "Es el proceso por el cual se cambian los valores de las columnas numéricas del conjunto de datos para usar una escala común, sin distorsionar las diferencias en los intervalos de valores ni perder información.\n",
    "\n",
    "Cabe resaltar que dicha normalización se utiliza cuando la data no es normal, es decir según la estadística aplicando algún test de normalidad (Shapiro-wilk, kolmogorov-smirnov, D'agostino, etc), si el **valor de P es menor a 0.05 se dice que la columna o variable no es normal**, por el contrario si el **valor de P es mayor a 0.05 se dice que los datos se encuntran en el segmento de confianza (95%) lo cual se asume como normal**.\n",
    "\n",
    "<span style=\"color:blue\">Nota: La normalización se usa cuando los valores no son normales según algun test aplicado y se ajustan los datos entre 0 y 1. Afecta los datos que ya estan en esa escala reduciendolos más.</span>\n",
    "\n",
    "2. **La Estandarización:**\n",
    "En aplicaciones prácticas, a menudo nos encontramos con un conjunto de datos que contiene una variedad de características, a menudo con diferentes distribuciones e intervalos, con diferentes niveles (dimensión), que es fácil de afectar nuestra capacitación modelo.La estandarización de datos es eliminar los efectos de la escala, la característica y las diferencias de distribución en el modelo.\n",
    "\n",
    "<span style=\"color:blue\">Nota: La estandarización se usa cuando los valores son normales según algun test aplicado y se ajustan los datos entre -1 y 1. No afecta los datos que ya estan en esa escala de 0 a 1.</span>\n",
    "\n",
    "#### Ejemplo Normalización y Estandarización:\n",
    "\n",
    "**Gráfico de caja para revisar el estado actual de los datos**\n",
    "\n",
    "dataF.plot.box()\n",
    "\n",
    "<img src=\"../Imagenes/grafcaja.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "**No hay normalidad en los datos al no tener las mismas medias. Se normaliza y los valores quedan de la siguiente manera. Se deben fijar que los valores están entre 0 y 1.**\n",
    "\n",
    "<img src=\"../Imagenes/grafcajados.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "**Para el segundo caso de estandarización se tomó la misma data. Se realiza el proceso y los valores quedan de la siguiente manera. Se deben fijar que los valores están entre -1 y 1.**\n",
    "\n",
    "<img src=\"../Imagenes/grafcajatres.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"10\">10. Correlación de Pearson y Spearman</a>\n",
    "<hr>\n",
    "El primer paso para entender la correlación y su significado es darnos cuenta que existen muchas manera de poder indentificar la relación entre las variables sea linear, monótona o independientes. Para esto como se evidencia en la figura existe un mecanismo para identificar dicho proceso.\n",
    "\n",
    "<img src=\"../Imagenes/analisis.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "Como se puede evidenciar para datos de tipo numérico se utiliza la famosa correlación de pearson o spearman las cuales determinan numéricamente cual es la relación existente entre una variable y otra.\n",
    "\n",
    "Esto se apoya con base en la covarianza que mide el grado de variación conjunta entre dos variables aleatorias. Existen diferentes tipos, de entre los que destacan el Pearson, Rho de Spearman y Tau de Kendall. Todos ellos comparten que:\n",
    "\n",
    "Su valor está comprendido en el rango [+1 , -1]. Siendo +1 una correlación positiva perfecta y -1 una correlación negativa perfecta.\n",
    "\n",
    "Se emplean como medida de la fuerza de asociación entre dos variables (tamaño del efecto):\n",
    "\n",
    "0: asociación nula.\n",
    "\n",
    "0.1: asociación pequeña.\n",
    "\n",
    "0.3: asociación mediana.\n",
    "\n",
    "0.5: asociación moderada.\n",
    "\n",
    "0.7: asociación alta.\n",
    "\n",
    "0.9: asociación muy alta.\n",
    "\n",
    "Desde el punto de vista práctico, las principales diferencias entre estos tres coeficientes son:\n",
    "\n",
    "La correlación de Pearson funciona bien con variables cuantitativas que tienen una distribución normal o próxima a la normal. Es más sensible a los valores extremos que las otras dos alternativas.\n",
    "\n",
    "La correlación de Spearman se emplea con variables cuantitativas (continuas o discretas). En lugar de utilizar directamente el valor de cada variable, los datos son ordenados y reemplazados por su respectivo orden ranking. Es un método no paramétrico muy utilizado cuando no se satisface la condición de normalidad necesaria para aplicar la correlación de Pearson.\n",
    "\n",
    "La correlación de Kendall es otra alternativa no paramétrica que, al igual que la correlación de Spearman, utiliza la ordenación de las observaciones ranking. Es recomendable cuando se dispone de pocos datos y muchos de ellos ocupan la misma posición en el rango, es decir, cuando hay muchas ligaduras.\n",
    "\n",
    "Ejemplo de Correlación modo Gráfico:\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,4))\n",
    "\n",
    "ax.scatter(x=datos.height, y=datos.weight, alpha= 0.8)\n",
    "\n",
    "ax.set_xlabel('Altura')\n",
    "\n",
    "ax.set_ylabel('Peso')\n",
    "\n",
    "<img src=\"../Imagenes/corr.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "## Correlaciones con Pandas\n",
    "\n",
    "print('Correlación Pearson: ', datos['weight'].corr(datos['height'], method='pearson'))\n",
    "\n",
    "print('Correlación spearman: ', datos['weight'].corr(datos['height'], method='spearman'))\n",
    "\n",
    "print('Correlación kendall: ', datos['weight'].corr(datos['height'], method='kendall'))\n",
    "\n",
    "## Correlaciones con Scipy\n",
    "\n",
    "r, p = stats.pearsonr(datos['weight'], datos['height'])\n",
    "print(f\"Correlación Pearson: r={r}, p-value={p}\")\n",
    "\n",
    "r, p = stats.spearmanr(datos['weight'], datos['height'])\n",
    "print(f\"Correlación Spearman: r={r}, p-value={p}\")\n",
    "\n",
    "r, p = stats.kendalltau(datos['weight'], datos['height'])\n",
    "print(f\"Correlación Pearson: r={r}, p-value={p}\")\n",
    "\n",
    "## Correlaciones con Pingouin\n",
    "\n",
    "display(pg.corr(datos['weight'], datos['height'], method='pearson'))\n",
    "\n",
    "display(pg.corr(datos['weight'], datos['height'], method='spearman'))\n",
    "\n",
    "display(pg.corr(datos['weight'], datos['height'], method='kendall'))\n",
    "\n",
    "## Matriz de Correlación\n",
    "\n",
    "corr_matrix = datos.corr(method='pearson')\n",
    "\n",
    "\n",
    "<img src=\"../Imagenes/tablatidy.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "<img src=\"../Imagenes/tablatidydos.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "## Grafica de matriz de correlación\n",
    "\n",
    "<img src=\"../Imagenes/graficacor.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "\n",
    "<img src=\"../Imagenes/graficacor2.png\" alt=\"banner\" style=\"display: block;\n",
    "  margin-left: auto;\n",
    "  margin-right: auto;\n",
    "  width: 60%;\">\n",
    "   \n",
    "\n",
    "[Volver a Casa](#11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más información sobre los temas tratados en el siguiente repositorio de Git: [Limpieza Taller](https://github.com/jaquimbayoc7/DocumentacionDiplomadoML/blob/master/LimpiezaTaller.ipynb) encontrarás el resumen en codigo Python 3.10. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Lecture Outline",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "a77b2f40ed1df9b9e0585d1a6edbb21462fc1256ebafb680e8b8391ecdeee36b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
